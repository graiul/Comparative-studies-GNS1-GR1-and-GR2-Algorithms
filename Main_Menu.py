import copy
import traceback
from collections import OrderedDict

from Query_Graph_Generator import Query_Graph_Generator
from DB_Access_Test import DB_Access_Test
from Dataset_Operator import Dataset_Operator
from STwig_Algorithm import STwig_Algorithm
# from Backtracking_STwig_Matching import Backtracking_STwig_Matching
from VF2Algorithm import VF2Algorithm
from neo4j_test_2 import neo4j_test_2
import os
from multiprocessing import Pool, Process, Manager, Lock

from timeit import default_timer as timer

from functools import partial

# https://stackoverflow.com/questions/6537487/changing-shell-text-color-windows
# https://pypi.org/project/colorama/
from colorama import init
from colorama import Fore, Back, Style
init()

def main():
    menu = [
        ["\n\n1. Graph generator tool"],
        ["2. Insert Zhao Sun data into db"],
        ["21. Insert RI data into db"],
        ["22. Insert small graph data into db"],
        ["3. Delete data from db"],
        ["4. View graph data - single thread"],
        ["5. View graph data - multi-threaded"],
        ["6. View graph data - multi-process"],
        ["7. Run MatchSTwig"],
        ["8. Run STwig_Order_Selection"],
        ["9. Run MatchSTwig per STwig generated by STwig_Order_Selection"],
        ["91. Run MatchSTwig *one process per STwig* generated by STwig_Order_Selection; unfiltered results"],
        ["92. Run MatchSTwig *one process per STwig* generated by STwig_Order_Selection; filtered results"],
        ["93. Small graph: Run MatchSTwig *one process per STwig* generated by STwig_Order_Selection; filtered results"],
        ["94. RI graph: Run MatchSTwig *one process per STwig* generated by STwig_Order_Selection; filtered results"],

        ["10. Query graph zhaosun split prototype, single threaded"],
        ["11. Configure db"],
        ["12. VF2 Algorithm"],
        ["0. Exit"]
    ]
    print()
    for m in menu:
        print(m)
    while(True):

        option = int(input('\nPlease choose option: '))
        # option = 12



        if option == 2:
            # node_dataset_url = str(input('\nDataset nodes URL: '))
            node_dataset_url = "https://raw.githubusercontent.com/room229/graph_datasets/master/ZhaoSun_Data_Graph_Nodes.csv"
            # edge_dataset_url = str(input('\nDataset edges URL: '))
            edge_dataset_url = "https://raw.githubusercontent.com/room229/graph_datasets/master/ZhaoSun_Data_Graph_Edges.csv"
            # leader_core_bolt_address = str(input('\nLeader core bolt address: '))
            leader_core_bolt_address = "http://localhost:7474/"
            # username = str(input('\nUsername of core: '))
            username = "neo4j"
            # passwd = str(input('\nPassword of core: '))
            passwd = "changeme"
            dataset_operator = Dataset_Operator(node_dataset_url, edge_dataset_url, leader_core_bolt_address, username, passwd)
            dataset_operator.insert_nodes_zhao_sun()
            dataset_operator.insert_edges_zhao_sun()
            print()
            for m in menu:
                print(m)

        elif option == 21:
            # node_dataset_url = str(input('\nDataset nodes URL: '))
            node_dataset_url = "https://raw.githubusercontent.com/room229/graph_datasets/master/RI_data_graph_nodes.csv"
            # edge_dataset_url = str(input('\nDataset edges URL: '))
            edge_dataset_url = "https://raw.githubusercontent.com/room229/graph_datasets/master/RI_data_graph_edges.csv"
            # leader_core_bolt_address = str(input('\nLeader core bolt address: '))
            leader_core_bolt_address = "http://localhost:7474/"
            # username = str(input('\nUsername of core: '))
            username = "neo4j"
            # passwd = str(input('\nPassword of core: '))
            passwd = "changeme"
            dataset_operator = Dataset_Operator(node_dataset_url, edge_dataset_url, leader_core_bolt_address, username, passwd)
            dataset_operator.insert_nodes_RI()
            option = str(input('\nStart inserting edges? (y/n): '))
            if option == "y":
                dataset_operator.insert_edges_RI()
            print()
            for m in menu:
                print(m)

        elif option == 22:
            node_dataset_url = "https://raw.githubusercontent.com/room229/graph_datasets/master/10_node_graph_nodes.csv"
            edge_dataset_url = "https://raw.githubusercontent.com/room229/graph_datasets/master/10_node_graph_edges.csv"
            # leader_core_bolt_address = str(input('\nLeader core bolt address: '))
            leader_core_bolt_address = "http://localhost:7474/"
            # username = str(input('\nUsername of core: '))
            username = "neo4j"
            # passwd = str(input('\nPassword of core: '))
            passwd = "changeme"
            dataset_operator = Dataset_Operator(node_dataset_url, edge_dataset_url, leader_core_bolt_address, username, passwd)
            dataset_operator.insert_nodes_small_graph()
            dataset_operator.insert_edges_small_graph()
            print()
            for m in menu:
                print(m)

        elif option == 3:
            # leader_core_bolt_address = str(input('\nLeader core bolt address: '))
            leader_core_bolt_address = "http://localhost:7474/"
            username = "neo4j"
            # username = str(input('\nUsername of core: '))
            passwd = "changeme"
            # passwd = str(input('\nPassword of core: '))
            dataset_operator = Dataset_Operator(None, None, leader_core_bolt_address, username, passwd)
            dataset_operator.delete_data_from_db()
            print()
            for m in menu:
                print(m)

        elif option == 4:
            print("\n================= Option 4 commencing... =================")
            test = DB_Access_Test()
            test.single_thread_access_to_one_read_replica()
            print("\n============== End of Option 4 execution =================")
            print()
            for m in menu:
                print(m)

        elif option == 5:
            print("\n================= Option 5 commencing... =================")
            test = DB_Access_Test()
            test.run_test_multiple_threads()
            print("\n============== End of Option 5 execution =================")
            print()
            for m in menu:
                print(m)

        elif option == 6:
            print("\n================= Option 6 commencing... =================")
            db = DB_Access_Test()
            queries = ["MATCH (n) RETURN n", "MATCH (n) RETURN n", "MATCH (n) RETURN n"]
            p = Pool(3)
            print("Pool result:")
            # res = p.map(foo.work, queries)
            start_time = timer()
            res = p.map(db.multiple_processes_access_to_one_read_replica, queries)
            total_time_sec = timer() - start_time
            total_time_millis = total_time_sec * 1000
            # print(res)
            for r in res:
                for rr in r:
                    print(rr)
                print()
            p.close()
            print()
            print('\x1b[0;30;45m' + 'DB_Access_Test multiple procs exec time: ' + str(
                total_time_millis) + ' ms' + '\x1b[0m')

            print("\n============== End of Option 6 execution =================")
            print()
            for m in menu:
                print(m)

        elif option == 7:
            print("\n================= Option 7 commencing... =================")
            # q = ['a', ['b', 'c']]
            # q = ['b', ['a', 'd', 'e']]
            q = ['d', ['c', 'f', 'e']]
            query_graph_gen = Query_Graph_Generator()
            query_graph = query_graph_gen.gen_zhaosun_query_graph()
            test2 = neo4j_test_2(query_graph)
            print("Searcing given STwigs from query graph in the data graph: ")
            start_time = timer()
            STwig_matches = test2.MatchSTwig(q)
            total_time_sec = timer() - start_time
            total_time_millis = total_time_sec * 1000
            print("\nSTwigs from data graph corresponding to the query STwig given: ")
            for match in STwig_matches:
                print(match)
            print('\x1b[0;30;45m' + 'Match STwig exec time: ' + str(
                total_time_millis) + ' ms' + '\x1b[0m')
            print("\n============== End of Option 7 execution =================")

        elif option == 8:
            print("\n================= Option 8 commencing... =================")
            print("STwig_Order_Selection: ")
            query_graph_gen = Query_Graph_Generator()
            query_graph = query_graph_gen.gen_zhaosun_query_graph()
            test2 = neo4j_test_2(query_graph)

            start_time = timer()
            stwigs = test2.STwig_Order_Selection()
            total_time_sec = timer() - start_time
            total_time_millis = total_time_sec * 1000
            for t in stwigs:
                print(t)

            print()
            print('\x1b[0;30;45m' + 'STwig Order Selection exec time: ' + str(
                total_time_millis) + ' ms' + '\x1b[0m')
            print("\n============== End of Option 8 execution =================")
            print()
            for m in menu:
                print(m)

        elif option == 9:
            print("\n================= Option 9 commencing... =================")
            query_graph_gen = Query_Graph_Generator()
            query_graph = query_graph_gen.gen_zhaosun_query_graph()
            test2 = neo4j_test_2(query_graph)

            start_time = timer()
            stwigs = test2.STwig_Order_Selection()

            print("stwigs:")
            print(stwigs)
            print("labels of stwigs:")
            print(query_graph.nodes(data=True))
            total_time_sec = timer() - start_time
            total_time_millis = total_time_sec * 1000
            # for t in stwigs:
            iteration_number = stwigs.index(stwigs[0])
            print("--------Iteration number: " + str(iteration_number) + str("-----------"))


            # test2.STwig_query_root = stwigs[0][0]

            test2.STwig_query_neighbor_labels = stwigs[0][1]

            # print("stwigs[0]:" + str(stwigs[0]))
            matches = test2.MatchSTwig(stwigs[0], iteration_number)
            test2.matches_dict[repr(stwigs[0])] = matches
            # print("matches for Iteration 0:")
            # print(matches)

            print("Matches dictionary: ")
            print("First key: ")
            print(list(test2.matches_dict.keys())[0])
            print('\x1b[0;30;45m' + "First values attached to the first key; matches: " + '\x1b[0m')
            for match in list(test2.matches_dict.values())[0]:
                print('\x1b[0;30;45m' + str(match) + '\x1b[0m')
            print("--------Iteration end-----------------")

            for t in stwigs[1:]:
                iteration_number = stwigs.index(t)
                print("--------Iteration number: " + str(iteration_number) + str("-----------"))
                test2.STwig_query_root = t[0]
                test2.STwig_query_neighbor_labels = t[1]
                matches = test2.MatchSTwig(t, iteration_number)
                # test2.matches_dict[repr(t)] = matches
                print("--------Iteration end-----------------")

            # print("STwig list:")
            # print(test2.stwig_list)

            print()
            print('\x1b[0;30;45m' + 'STwig Order Selection exec time: ' + str(
                total_time_millis) + ' ms' + '\x1b[0m')
            print("\n============== End of Option 9 execution =================")

        elif option == 91:
            print("\n================= Option 91 commencing... =================")
            query_graph_gen = Query_Graph_Generator()
            query_graph = query_graph_gen.gen_zhaosun_query_graph()
            test2 = neo4j_test_2(query_graph)

            start_time = timer()
            stwigs = test2.STwig_Order_Selection()

            # Initiem un process pool cu numarul de procese egal cu cel al STwig-urilor generate de STwig_Order_Selection
            pool = Pool(len(stwigs))
            print("Pool: " + str(pool))
            # Avem un dictionar care va stoca rezultatele fiecarui process.
            # Acest dictionar este o zona de memorie comuna al proceselor, iar ordinea cheilor(ordinea in care
            # stocam datele de iesire) nu conteaza.
            # Va trebui sa punem o bariera, astfel incat atunci cand fiecare proces cauta in dictionar,
            # toate procesele trebuie sa fi pus deja rezultatele lor in el.

            manager = Manager()
            process_dict = manager.dict()
            # pool.


            # Pentru fiecare proces rulam o metoda de gasire al matches pentru un singur STwig
            # Avem doua cazuri: primul STwig care trebuie cautat cu totul in graful data
            # si urmatoarele, dar care vor fi bounded de primul, deci radacinile lor sunt deja stabilite.
            test2.STwig_query_neighbor_labels = stwigs[0][1]
            # db.match_finding_process(stwigs[0], 0, test2)
            db = DB_Access_Test()

            return_dict = manager.dict()
            # func = partial(db.match_finding_process, [stwigs[0]])
            # res = pool.map(db.match_finding_process, [stwigs[0]])
            # print(res)

            process = Process(target=db.match_finding_process, args=(stwigs[0], return_dict, ))
            process.start()
            process.join()
            print(return_dict.values())

            jobs = []

            for t in stwigs[1:]:
                process = Process(target=db.match_finding_process, args=(t, return_dict, ))
                jobs.append(process)

            for j in jobs:
                j.start()
                j.join()
                print(return_dict.values())

            # for t in stwigs[1:]:
            #     iteration_number = stwigs.index(t)
            #     print("--------Iteration number: " + str(iteration_number) + str("-----------"))
            #     test2.STwig_query_root = t[0]
            #     test2.STwig_query_neighbor_labels = t[1]
            #     matches = test2.MatchSTwig(t, iteration_number)
            #     # test2.matches_dict[repr(t)] = matches
            #     print("--------Iteration end-----------------")

            print("\n============== End of Option 91 execution =================")

        elif option == 92:
            print("\n================= Option 92 commencing... =================")
            query_graph_gen = Query_Graph_Generator()
            # query_graph = query_graph_gen.gen_zhaosun_query_graph()
            query_graph = query_graph_gen.gen_RI_query_graph()
            print(query_graph.nodes(data=True))

            manager = Manager()
            return_dict = manager.dict()
            used_stwigs = manager.list()
            STwig_query_neighbor_labels = manager.list()

            STwig_algorithm = STwig_Algorithm(query_graph, return_dict, used_stwigs, STwig_query_neighbor_labels)
            stwigs = STwig_algorithm.STwig_Order_Selection()
            print("stwigs: " + str(stwigs))
            db = DB_Access_Test()


            # process = Process(target=db.match_finding_process_filtered, args=(stwigs[0], return_dict, STwig_query_neighbor_labels, query_graph, iter_num, ))
            # process.start()
            # process.join()

            jobs = []

            # for t in stwigs[1:]:
            for t in stwigs:
                iter_num = stwigs.index(t)
                process = Process(target=db.match_finding_process_filtered, args=(t, return_dict, STwig_query_neighbor_labels, query_graph, iter_num, used_stwigs, ))
                jobs.append(process)


            for j in jobs:
                j.start()
                j.join()

            print("Results from multiprocessing: ")
            for item in return_dict.items():
                print(item)



            print("\n============== End of Option 92 execution =================")

        elif option == 93:
            print("\n================= Option 93 commencing... =================")
            query_graph_gen = Query_Graph_Generator()
            # query_graph = query_graph_gen.gen_zhaosun_query_graph()
            query_graph = query_graph_gen.gen_small_graph_query_graph()
            print(query_graph.nodes(data=True))

            manager = Manager()
            return_dict = manager.dict()
            used_stwigs = manager.list()
            STwig_query_neighbor_labels = manager.list()

            STwig_algorithm = STwig_Algorithm(query_graph, return_dict, used_stwigs, STwig_query_neighbor_labels)
            stwigs = STwig_algorithm.STwig_Order_Selection()
            print("stwigs: " + str(stwigs))
            db = DB_Access_Test()

            jobs = []

            for t in stwigs:
                iter_num = stwigs.index(t)
                process = Process(target=db.match_finding_process_filtered, args=(t, return_dict, STwig_query_neighbor_labels, query_graph, iter_num, used_stwigs, ))
                jobs.append(process)

            for j in jobs:
                j.start()
                j.join()

            print("Results from multiprocessing: ")
            for item in return_dict.values():
                for i in item:
                    print(i)



            print("\n============== End of Option 93 execution =================")


        elif option == 94:
            print("\n================= Option 94 commencing... =================")
            query_graph_gen = Query_Graph_Generator()
            # query_graph = query_graph_gen.gen_zhaosun_query_graph()
            # query_graph = query_graph_gen.gen_small_graph_query_graph()
            query_graph = query_graph_gen.gen_RI_query_graph()
            print("Query graph nodes and labels: ")
            print(query_graph.nodes(data=True))

            manager = Manager()
            return_dict = manager.dict()
            used_stwigs = manager.list()
            STwig_query_neighbor_labels = manager.list()
            shared_sorted_leafs_to_be_roots = manager.list()

            lock = Lock()

            STwig_algorithm = STwig_Algorithm(query_graph, return_dict, used_stwigs, STwig_query_neighbor_labels, lock)
            stwigs = STwig_algorithm.STwig_Order_Selection()
            print("STwigs generated by STwig_Order_Selection() from the query graph: " + str(stwigs))
            db = DB_Access_Test()

            jobs = []

            # Paralelizat, fara filtrare.
            # producer = Process(target=db.match_finding_process_producer, args=(stwigs[0], return_dict, STwig_query_neighbor_labels, query_graph, 0, used_stwigs, lock, ))
            # producer2 = Process(target=db.match_finding_process_producer, args=(stwigs[1], return_dict, STwig_query_neighbor_labels, query_graph, 0, used_stwigs, lock, ))
            # producer3 = Process(target=db.match_finding_process_producer, args=(stwigs[2], return_dict, STwig_query_neighbor_labels, query_graph, 0, used_stwigs, lock, ))
            # # filterer = Process(target=db.filter_results_process, args=(stwigs[1], return_dict, stwigs[1][1], query_graph, used_stwigs, lock, shared_sorted_leafs_to_be_roots, ))
            # prod_com = [producer, producer2, producer3]
            #
            # # start_time = timer()
            #
            # for pc in prod_com:
            #     pc.start()
            #     # pc.join()
            #
            # for pc in prod_com:
            #     pc.join()


            # print()
            # print("STwig_query_neighbor_labels - must not be empty")
            # print(STwig_query_neighbor_labels)


            # Neparalelizat, cu filtrare.
            for t in stwigs:
                iter_num = stwigs.index(t)
                process = Process(target=db.match_finding_process_producer, args=(stwigs[0], return_dict, STwig_query_neighbor_labels, query_graph, 0, used_stwigs, lock, ))
                jobs.append(process)

            start_time = timer()
            for j in jobs:
                j.start()
                # print('PID is ' + str(j.pid))
                # print(os.getpid())
                # started_processes.append(j)
                # print(j.is_alive())
                j.join()
            #
            # total_time = (timer() - start_time) * 1000
            #

            # f2 = open("f2.txt", "w+")
            print("Results from STwig Algorithm: ")
            for item in return_dict.values():
                # print(item)
                for i in item:
                    print(i)
                    # f2.write(str(i)+"\n")
            # f2.close()

            # print()
            # print("Total exec time: " + str(total_time))

            # print()
            # print("used_stwigs: ")
            # for us in used_stwigs:
            #     print(us)

            # for q in stwigs:
            # q = stwigs[1]
            # STwig_query_neighbors = q[1]
            # STwig_algorithm.filter_results(q, STwig_query_neighbors)


            print("\n============== End of Option 94 execution =================")


        elif option == 10:
            print("\n================= Option 10 commencing... =================")
            # print("Are these the query graph STWIGS?")
            query_graph_gen = Query_Graph_Generator()
            query_graph = query_graph_gen.gen_zhaosun_query_graph()
            test2 = neo4j_test_2()
            query_graph_gen = Query_Graph_Generator()
            query_graph = query_graph_gen.gen_zhaosun_query_graph()
            splits = test2.Query_Graph_Split(query_graph)
            for s in splits:
                print(str(splits))
            print("\n============== End of Option 10 execution =================")

        elif option == 11:
            file = "notepad.exe neo4j_db\\docker-compose.yml"
            os.system(file)

        elif option == 12:
            print("\nVF2 Algorithm: ")

            # TRANSFORMA IN INT DIN STR IN CREAREA GRAFULUI NX! - Facut.

            # M = [["0", "0"]]  # Test de corectitudine. Ar trebui sa dea un M in care toate match-urile sa aiba elemente egale, practic sa imi returneze toate nodurile query asociate cu ele insasi.
            # M = [["0", "1173"]] # Test al timpului de executie.
            # vf2 = VF2Algorithm(M, 'graph_to_RI_db.txt', 'Homo_sapiens_udistr_32.gfd', 'RI')

            # M = [["1","1"]]
            # M = [[1, 5]]
            # M = [["1","9"]]
            # print(M)

            # vf2 = VF2Algorithm(M)
            # vf2.subGraphSearch(M)

            # vf2 = VF2Algorithm(M, 'small_query_graph_VF2.txt', 'small_data_graph_VF2.txt', 'RI')
            # vf2.subGraphSearch(M)


            M = []
            results = []
            # print("Query graph choice: for Small data graph or RI data graph? (sm/ri)")
            # graph_choice = str(input())
            start_time = timer()
            if len(M) == 0:
                # Pentru radacini nu am mai facut pruning!
                # Pentru fiecare radacina din lista de radacini,
                # din rezultatul final voi elimina radacinile care nu au fost folosite
                # pentru executia respectiva a algoritmului.

                M_list_main = []

                print("\nRoots search beginning: ")
                # vf2 = VF2Algorithm(M, 'small_query_graph_VF2.txt', 'small_data_graph_VF2.txt', 'RI')
                # exit(0)

                # vf2 = VF2Algorithm(M, graph_choice)
                vf2 = VF2Algorithm(M)


                roots = vf2.subGraphSearch(M)[1]
                vf2.results_dict.clear()

                print()
                print("Roots found: ")
                print(roots)
                print()
                # print("Selected root: ")
                for root in roots:
                    # print(root)

                    # Alegem noi primul nod al grafului query:
                    # Pentru small graph
                    # M2 = [[1, root]]

                    # Pentru RI graph
                    # M2 = [[1773, root]] # Algoritmul va schimba al doilea element doar.
                    # print("M2 = " + str(M2))

                    # if graph_choice == "sm":
                    #     M2 = [[1, root]]

                    # if graph_choice == "ri":
                        # M2 = [[1773, root]]
                        # M2 = [[1488, root]]
                        # M2 = [[1898, root]]
                        # M2 = [[0, root]]
                        # M2 = [[7190, root]]
                        # M2 = [[269, root]]

                    M2 = [[6523, root]]



                        # print()
                        # print("Query root node: " + str(root))

                    # vf2 = VF2Algorithm(M, 'small_query_graph_VF2.txt', 'small_data_graph_VF2.txt', 'RI')
                    # vf2_2 = VF2Algorithm(M2, graph_choice)
                    vf2_2 = VF2Algorithm(M2)

                    execution_flag = vf2_2.subGraphSearch(M2)
                    M_list_main.append(execution_flag)
                    # vf2 = None

                    # Pentru small graph
                    # results.append([["Query root: " + "1"], ["Data root: " + str(root)], [list(vf2_2.results_dict.items())[1:]]])
                    # Pentru RI graph
                    # results.append([["Query root: " + "1773"], ["Data root: " + str(root)], [list(vf2_2.results_dict.items())[1:]]])
                    if execution_flag == None:
                        # if graph_choice == "sm":
                        #     print(Fore.LIGHTGREEN_EX + str([["Query root: " + "1"], ["Data root: " + str(root)],
                        #                                     [list(vf2_2.results_dict.items())[1:]]]))
                        #     print(Style.RESET_ALL)

                        # if graph_choice == "ri":
                        # if len(list(vf2_2.results_dict.items())) > 0:

                        leafs = copy.deepcopy(list(vf2_2.results_dict.items()))
                        leafs.insert(0, root)
                        res = copy.deepcopy(leafs)
                        print("Results from VF2 Algorithm: ")
                        if len(res) == len(vf2_2.queryGraph.nodes()):
                            print(Fore.LIGHTGREEN_EX + "Data root: " + str(root))
                            print(res)
                            # print(len(res))
                            # print(list(vf2_2.results_dict.items())[0])
                            print(Style.RESET_ALL)
                            vf2_2.results_dict.clear()


            total_time_sec = timer() - start_time
            print("Execution time for VF2 Algorithm (seconds): ")
            print(total_time_sec)

                    # print(Fore.LIGHTBLUE_EX + "\nShow results found until now? (y/n): ")
                    # i = input()
                    # if i == "y":
                    #     break
                    # print(Style.RESET_ALL)

            # print(Fore.GREEN + "\nFinal results: ")
            # for result in results:
            #     print(result)
            # print(Style.RESET_ALL)

        # elif option == 13:
        #     ##################################################################
        #
        #     # GRAFUL DATA DIN NEO4J
        #     # neograph_data = Graph("bolt://127.0.0.1:7690", auth=("neo4j", "changeme")) # Data Graph RI - Cluster Neo4J
        #     neograph_data = Graph("bolt://127.0.0.1:7687",
        #                           auth=("neo4j", "changeme"))  # Data Graph RI - O singura instanta de Neo4J
        #
        #     cqlQuery = "MATCH p=(n)-[r:PPI]->(m) return n.node_id, m.node_id"
        #     result = neograph_data.run(cqlQuery).to_ndarray()
        #     edge_list = result.tolist()
        #     # print("edge_list: ")
        #     # print(edge_list)
        #     edge_list_integer_ids = []
        #     for string_edge in edge_list:
        #         edge_list_integer_ids.append([int(i) for i in string_edge])
        #     # print("edge_list_integer_ids: ")
        #     # print(edge_list_integer_ids)
        #
        #     dataGraph = nx.Graph()
        #     dataGraph.add_edges_from(sorted(edge_list_integer_ids))
        #     cqlQuery2 = "MATCH (n) return n.node_id, n.node_label"
        #     result2 = neograph_data.run(cqlQuery2).to_ndarray()
        #     # print("result2: ")
        #     # print(result2)
        #     node_ids_as_integers_with_string_labels = []
        #     for node in result2:
        #         # print(node[0])
        #         node_ids_as_integers_with_string_labels.append([int(node[0]), node[1]])
        #     # print("node_ids_as_integers_with_string_labels: ")
        #     # print(node_ids_as_integers_with_string_labels)
        #
        #     node_attr_dict = OrderedDict(sorted(node_ids_as_integers_with_string_labels))
        #     nx.set_node_attributes(dataGraph, node_attr_dict, 'label')
        #     #############################################################################
        #
        #     # # FUNCTIONAL:
        #     # query_stwig_1 = [1, 2, 3, 4]
        #     # # query_stwig_1 = [1, 2, 3]
        #     # # query_stwig_1 = [2, 3, 4]
        #     # # query_stwig_1 = [1, 2]
        #     # # query_stwig_1 = [3, 10]
        #     # # query_stwig_1 = [4, 10]
        #     #
        #     #
        #     # print("Query STwig: " + str(query_stwig_1))
        #     # # Label-ul radacinii
        #     # root_label = small_graph.node[query_stwig_1[0]]['label']
        #     # # Label-urile vecinilor din lista
        #     # neighbor_labels = []
        #     # for n in query_stwig_1[1:]:
        #     #     neighbor_labels.append(small_graph.node[n]['label'])
        #     #
        #     # query_stwig_1_as_labels = []
        #     # query_stwig_1_as_labels.append(root_label)
        #     # for nl in neighbor_labels:
        #     #     query_stwig_1_as_labels.append(nl)
        #     # print("query_stwig_1_as_labels: " + str(query_stwig_1_as_labels))
        #     # print()
        #     # query_stwig_1_as_labels_source = copy.deepcopy(query_stwig_1_as_labels)
        #     #
        #     # query_stwig1_dict = OrderedDict(zip(query_stwig_1, query_stwig_1_as_labels_source))
        #     # print("query_stwig1_dict: ")
        #     # print(query_stwig1_dict.items())
        #     # print()
        #     # p_solution = []
        #     # complete_solutions = []
        #     # positions = OrderedDict().fromkeys([0,1,2,3])
        #     # positions[0] = []
        #     # positions[1] = []
        #     # positions[2] = []
        #     # positions[3] = []
        #     # print(positions.items())
        #     # node_list_aux = copy.deepcopy(list(small_graph.nodes()))
        #     #######################################################################################
        #
        #     # FUNCTIONAL:
        #     # query_stwig_1 = [1773, 1488, 1898, 2285]
        #
        #     # Aici cream un obiect graf query:
        #     query_graph_gen = Query_Graph_Generator()
        #     query_graph = query_graph_gen.gen_RI_query_graph()
        #     query_stwig_1 = list(query_graph.nodes())
        #     print("Query STwig: " + str(query_stwig_1))
        #     # Label-ul radacinii
        #     # root_label = dataGraph.node[query_stwig_1[0]]['label']
        #     root_label = query_graph.node[query_stwig_1[0]]['label']
        #     # Label-urile vecinilor din lista
        #     neighbor_labels = []
        #     for n in query_stwig_1[1:]:
        #         # neighbor_labels.append(dataGraph.node[n]['label'])
        #         neighbor_labels.append(query_graph.node[n]['label'])
        #
        #     query_stwig_1_as_labels = []
        #     query_stwig_1_as_labels.append(root_label)
        #     for nl in neighbor_labels:
        #         query_stwig_1_as_labels.append(nl)
        #     print("query_stwig_1_as_labels: " + str(query_stwig_1_as_labels))
        #     print()
        #     query_stwig_1_as_labels_source = copy.deepcopy(query_stwig_1_as_labels)
        #
        #     query_stwig1_dict = OrderedDict(zip(query_stwig_1, query_stwig_1_as_labels_source))
        #     print("query_stwig1_dict: ")
        #     print(query_stwig1_dict.items())
        #     print()
        #     p_solution = []
        #     complete_solutions = []
        #     positions = OrderedDict().fromkeys([0, 1, 2, 3])
        #     positions[0] = []
        #     positions[1] = []
        #     positions[2] = []
        #     positions[3] = []
        #     print("Positions log: ")
        #     print(positions.items())
        #     node_list_aux = copy.deepcopy(list(dataGraph.nodes()))
        #     ####################################################################################
        #
        #     # Fisier text:
        #     f1 = open("f1.txt", "w+")
        #
        #     # Executia algoritmului Backtracking:
        #     backtracking = Backtracking_STwig_Matching()
        #     try:
        #         # subgraph_search(p_solution, query_stwig1_dict, [], small_graph)
        #         start_time = timer()
        #         subgraph_search(p_solution, query_stwig1_dict, [], dataGraph)
        #         total_time = timer() - start_time
        #         print("Timp total de executare algoritm Backtracking: " + str(total_time) + " secunde.")
        #     except IndexError:
        #         tb = traceback.format_exc()
        #         print(tb)
        #     except SystemExit:
        #         exit(0)

        elif option == 0:
            exit(code=0)

if __name__ == '__main__':
    main()