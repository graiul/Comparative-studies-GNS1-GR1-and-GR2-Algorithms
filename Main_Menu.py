import copy
import itertools
import math
import traceback
from collections import OrderedDict

from py2neo import Graph
import networkx as nx

from GR2_Algorithm import GR2_Algorithm
from Query_Graph_Generator import Query_Graph_Generator

# from DB_Access_Test import DB_Access_Test
from Dataset_Operator import Dataset_Operator

# from STwig_Algorithm import STwig_Algorithm
# from Backtracking_STwig_Matching import Backtracking_STwig_Matching
# from VF2Algorithm import VF2Algorithm
from GR1_Algorithm import GR1_Algorithm

from Toolbox_Gheorghica_Radu_Iulian import Toolbox_Gheorghica_Radu_Iulian as tgri

# from neo4j_test_2 import neo4j_test_2
import os
# from multiprocessing import Pool, Process, Manager, Lock

from timeit import default_timer as timer

from functools import partial

# https://stackoverflow.com/questions/6537487/changing-shell-text-color-windows
# https://pypi.org/project/colorama/
# from colorama import init
# from colorama import Fore, Back, Style
# init()

def main():
    menu = [
        # ["\n\n1. Graph generator tool"],
        # ["2. Insert Zhao Sun data into db"],
        # ["21. Insert RI data into db"],
        # ["22. Insert small graph data into db"],
        # ["3. Delete data from db"],
        # ["4. View graph data - single thread"],
        # ["5. View graph data - multi-threaded"],
        # ["6. View graph data - multi-process"],
        # ["7. Run MatchSTwig"],
        # ["8. Run STwig_Order_Selection"],
        # ["9. Run MatchSTwig per STwig generated by STwig_Order_Selection"],
        # ["91. Run MatchSTwig *one process per STwig* generated by STwig_Order_Selection; unfiltered results"],
        # ["92. Run MatchSTwig *one process per STwig* generated by STwig_Order_Selection; filtered results"],
        # ["93. Small graph: Run MatchSTwig *one process per STwig* generated by STwig_Order_Selection; filtered results"],
        ["94. RI graph: Run MatchSTwig *one process per STwig* generated by STwig_Order_Selection; filtered results"],

        # ["10. Query graph zhaosun split prototype, single threaded"],
        # ["11. Configure db"],
        ["12. VF2 Algorithm"],
        ["13. GR1 Algorithm"],
        ["14. GR2 Algorithm"],

        ["0. Exit"]
    ]
    print()
    for m in menu:
        print(m)
    # while(True):
    option = int(input('\nPlease choose option: '))
        # option = 12



    if option == 2:
        # node_dataset_url = str(input('\nDataset nodes URL: '))
        node_dataset_url = "https://raw.githubusercontent.com/room229/graph_datasets/master/ZhaoSun_Data_Graph_Nodes.csv"
        # edge_dataset_url = str(input('\nDataset edges URL: '))
        edge_dataset_url = "https://raw.githubusercontent.com/room229/graph_datasets/master/ZhaoSun_Data_Graph_Edges.csv"
        # leader_core_bolt_address = str(input('\nLeader core bolt address: '))
        leader_core_bolt_address = "http://localhost:7474/"
        # username = str(input('\nUsername of core: '))
        username = "neo4j"
        # passwd = str(input('\nPassword of core: '))
        passwd = "changeme"
        dataset_operator = Dataset_Operator(node_dataset_url, edge_dataset_url, leader_core_bolt_address, username, passwd)
        dataset_operator.insert_nodes_zhao_sun()
        dataset_operator.insert_edges_zhao_sun()
        print()
        for m in menu:
            print(m)

    elif option == 21:
        # node_dataset_url = str(input('\nDataset nodes URL: '))
        node_dataset_url = "https://raw.githubusercontent.com/room229/graph_datasets/master/RI_data_graph_nodes.csv"
        # edge_dataset_url = str(input('\nDataset edges URL: '))
        edge_dataset_url = "https://raw.githubusercontent.com/room229/graph_datasets/master/RI_data_graph_edges.csv"
        # leader_core_bolt_address = str(input('\nLeader core bolt address: '))
        leader_core_bolt_address = "http://localhost:7474/"
        # username = str(input('\nUsername of core: '))
        username = "neo4j"
        # passwd = str(input('\nPassword of core: '))
        passwd = "changeme"
        dataset_operator = Dataset_Operator(node_dataset_url, edge_dataset_url, leader_core_bolt_address, username, passwd)
        dataset_operator.insert_nodes_RI()
        option = str(input('\nStart inserting edges? (y/n): '))
        if option == "y":
            dataset_operator.insert_edges_RI()
        print()
        for m in menu:
            print(m)

    elif option == 22:
        node_dataset_url = "https://raw.githubusercontent.com/room229/graph_datasets/master/10_node_graph_nodes.csv"
        edge_dataset_url = "https://raw.githubusercontent.com/room229/graph_datasets/master/10_node_graph_edges.csv"
        # leader_core_bolt_address = str(input('\nLeader core bolt address: '))
        leader_core_bolt_address = "http://localhost:7474/"
        # username = str(input('\nUsername of core: '))
        username = "neo4j"
        # passwd = str(input('\nPassword of core: '))
        passwd = "changeme"
        dataset_operator = Dataset_Operator(node_dataset_url, edge_dataset_url, leader_core_bolt_address, username, passwd)
        dataset_operator.insert_nodes_small_graph()
        dataset_operator.insert_edges_small_graph()
        print()
        for m in menu:
            print(m)

    elif option == 3:
        # leader_core_bolt_address = str(input('\nLeader core bolt address: '))
        leader_core_bolt_address = "http://localhost:7474/"
        username = "neo4j"
        # username = str(input('\nUsername of core: '))
        passwd = "changeme"
        # passwd = str(input('\nPassword of core: '))
        dataset_operator = Dataset_Operator(None, None, leader_core_bolt_address, username, passwd)
        dataset_operator.delete_data_from_db()
        print()
        for m in menu:
            print(m)

    elif option == 4:
        print("\n================= Option 4 commencing... =================")
        test = DB_Access_Test()
        test.single_thread_access_to_one_read_replica()
        print("\n============== End of Option 4 execution =================")
        print()
        for m in menu:
            print(m)

    elif option == 5:
        print("\n================= Option 5 commencing... =================")
        test = DB_Access_Test()
        test.run_test_multiple_threads()
        print("\n============== End of Option 5 execution =================")
        print()
        for m in menu:
            print(m)

    elif option == 6:
        print("\n================= Option 6 commencing... =================")
        db = DB_Access_Test()
        queries = ["MATCH (n) RETURN n", "MATCH (n) RETURN n", "MATCH (n) RETURN n"]
        p = Pool(3)
        print("Pool result:")
        # res = p.map(foo.work, queries)
        start_time = timer()
        res = p.map(db.multiple_processes_access_to_one_read_replica, queries)
        total_time_sec = timer() - start_time
        total_time_millis = total_time_sec * 1000
        # print(res)
        for r in res:
            for rr in r:
                print(rr)
            print()
        p.close()
        print()
        print('\x1b[0;30;45m' + 'DB_Access_Test multiple procs exec time: ' + str(
            total_time_millis) + ' ms' + '\x1b[0m')

        print("\n============== End of Option 6 execution =================")
        print()
        for m in menu:
            print(m)

    elif option == 7:
        print("\n================= Option 7 commencing... =================")
        # q = ['a', ['b', 'c']]
        # q = ['b', ['a', 'd', 'e']]
        q = ['d', ['c', 'f', 'e']]
        query_graph_gen = Query_Graph_Generator()
        query_graph = query_graph_gen.gen_zhaosun_query_graph()
        test2 = neo4j_test_2(query_graph)
        print("Searcing given STwigs from query graph in the data graph: ")
        start_time = timer()
        STwig_matches = test2.MatchSTwig(q)
        total_time_sec = timer() - start_time
        total_time_millis = total_time_sec * 1000
        print("\nSTwigs from data graph corresponding to the query STwig given: ")
        for match in STwig_matches:
            print(match)
        print('\x1b[0;30;45m' + 'Match STwig exec time: ' + str(
            total_time_millis) + ' ms' + '\x1b[0m')
        print("\n============== End of Option 7 execution =================")

    elif option == 8:
        print("\n================= Option 8 commencing... =================")
        print("STwig_Order_Selection: ")
        query_graph_gen = Query_Graph_Generator()
        query_graph = query_graph_gen.gen_zhaosun_query_graph()
        test2 = neo4j_test_2(query_graph)

        start_time = timer()
        stwigs = test2.STwig_Order_Selection()
        total_time_sec = timer() - start_time
        total_time_millis = total_time_sec * 1000
        for t in stwigs:
            print(t)

        print()
        print('\x1b[0;30;45m' + 'STwig Order Selection exec time: ' + str(
            total_time_millis) + ' ms' + '\x1b[0m')
        print("\n============== End of Option 8 execution =================")
        print()
        for m in menu:
            print(m)

    elif option == 9:
        print("\n================= Option 9 commencing... =================")
        query_graph_gen = Query_Graph_Generator()
        query_graph = query_graph_gen.gen_zhaosun_query_graph()
        test2 = neo4j_test_2(query_graph)

        start_time = timer()
        stwigs = test2.STwig_Order_Selection()

        print("stwigs:")
        print(stwigs)
        print("labels of stwigs:")
        print(query_graph.nodes(data=True))
        total_time_sec = timer() - start_time
        total_time_millis = total_time_sec * 1000
        # for t in stwigs:
        iteration_number = stwigs.index(stwigs[0])
        print("--------Iteration number: " + str(iteration_number) + str("-----------"))


        # test2.STwig_query_root = stwigs[0][0]

        test2.STwig_query_neighbor_labels = stwigs[0][1]

        # print("stwigs[0]:" + str(stwigs[0]))
        matches = test2.MatchSTwig(stwigs[0], iteration_number)
        test2.matches_dict[repr(stwigs[0])] = matches
        # print("matches for Iteration 0:")
        # print(matches)

        print("Matches dictionary: ")
        print("First key: ")
        print(list(test2.matches_dict.keys())[0])
        print('\x1b[0;30;45m' + "First values attached to the first key; matches: " + '\x1b[0m')
        for match in list(test2.matches_dict.values())[0]:
            print('\x1b[0;30;45m' + str(match) + '\x1b[0m')
        print("--------Iteration end-----------------")

        for t in stwigs[1:]:
            iteration_number = stwigs.index(t)
            print("--------Iteration number: " + str(iteration_number) + str("-----------"))
            test2.STwig_query_root = t[0]
            test2.STwig_query_neighbor_labels = t[1]
            matches = test2.MatchSTwig(t, iteration_number)
            # test2.matches_dict[repr(t)] = matches
            print("--------Iteration end-----------------")

        # print("STwig list:")
        # print(test2.stwig_list)

        print()
        print('\x1b[0;30;45m' + 'STwig Order Selection exec time: ' + str(
            total_time_millis) + ' ms' + '\x1b[0m')
        print("\n============== End of Option 9 execution =================")

    elif option == 91:
        print("\n================= Option 91 commencing... =================")
        query_graph_gen = Query_Graph_Generator()
        query_graph = query_graph_gen.gen_zhaosun_query_graph()
        test2 = neo4j_test_2(query_graph)

        start_time = timer()
        stwigs = test2.STwig_Order_Selection()

        # Initiem un process pool cu numarul de procese egal cu cel al STwig-urilor generate de STwig_Order_Selection
        pool = Pool(len(stwigs))
        print("Pool: " + str(pool))
        # Avem un dictionar care va stoca rezultatele fiecarui process.
        # Acest dictionar este o zona de memorie comuna al proceselor, iar ordinea cheilor(ordinea in care
        # stocam datele de iesire) nu conteaza.
        # Va trebui sa punem o bariera, astfel incat atunci cand fiecare proces cauta in dictionar,
        # toate procesele trebuie sa fi pus deja rezultatele lor in el.

        manager = Manager()
        process_dict = manager.dict()
        # pool.


        # Pentru fiecare proces rulam o metoda de gasire al matches pentru un singur STwig
        # Avem doua cazuri: primul STwig care trebuie cautat cu totul in graful data
        # si urmatoarele, dar care vor fi bounded de primul, deci radacinile lor sunt deja stabilite.
        test2.STwig_query_neighbor_labels = stwigs[0][1]
        # db.match_finding_process(stwigs[0], 0, test2)
        db = DB_Access_Test()

        return_dict = manager.dict()
        # func = partial(db.match_finding_process, [stwigs[0]])
        # res = pool.map(db.match_finding_process, [stwigs[0]])
        # print(res)

        process = Process(target=db.match_finding_process, args=(stwigs[0], return_dict, ))
        process.start()
        process.join()
        print(return_dict.values())

        jobs = []

        for t in stwigs[1:]:
            process = Process(target=db.match_finding_process, args=(t, return_dict, ))
            jobs.append(process)

        for j in jobs:
            j.start()
            j.join()
            print(return_dict.values())

        # for t in stwigs[1:]:
        #     iteration_number = stwigs.index(t)
        #     print("--------Iteration number: " + str(iteration_number) + str("-----------"))
        #     test2.STwig_query_root = t[0]
        #     test2.STwig_query_neighbor_labels = t[1]
        #     matches = test2.MatchSTwig(t, iteration_number)
        #     # test2.matches_dict[repr(t)] = matches
        #     print("--------Iteration end-----------------")

        print("\n============== End of Option 91 execution =================")

    elif option == 92:
        print("\n================= Option 92 commencing... =================")
        query_graph_gen = Query_Graph_Generator()
        # query_graph = query_graph_gen.gen_zhaosun_query_graph()
        query_graph = query_graph_gen.gen_RI_query_graph()
        print(query_graph.nodes(data=True))

        manager = Manager()
        return_dict = manager.dict()
        used_stwigs = manager.list()
        STwig_query_neighbor_labels = manager.list()

        STwig_algorithm = STwig_Algorithm(query_graph, return_dict, used_stwigs, STwig_query_neighbor_labels)
        stwigs = STwig_algorithm.STwig_Order_Selection()
        print("stwigs: " + str(stwigs))
        db = DB_Access_Test()


        # process = Process(target=db.match_finding_process_filtered, args=(stwigs[0], return_dict, STwig_query_neighbor_labels, query_graph, iter_num, ))
        # process.start()
        # process.join()

        jobs = []

        # for t in stwigs[1:]:
        for t in stwigs:
            iter_num = stwigs.index(t)
            process = Process(target=db.match_finding_process_filtered, args=(t, return_dict, STwig_query_neighbor_labels, query_graph, iter_num, used_stwigs, ))
            jobs.append(process)


        for j in jobs:
            j.start()
            j.join()

        print("Results from multiprocessing: ")
        for item in return_dict.items():
            print(item)



        print("\n============== End of Option 92 execution =================")

    elif option == 93:
        print("\n================= Option 93 commencing... =================")
        query_graph_gen = Query_Graph_Generator()
        # query_graph = query_graph_gen.gen_zhaosun_query_graph()
        query_graph = query_graph_gen.gen_small_graph_query_graph()
        print(query_graph.nodes(data=True))

        manager = Manager()
        return_dict = manager.dict()
        used_stwigs = manager.list()
        STwig_query_neighbor_labels = manager.list()

        STwig_algorithm = STwig_Algorithm(query_graph, return_dict, used_stwigs, STwig_query_neighbor_labels)
        stwigs = STwig_algorithm.STwig_Order_Selection()
        print("stwigs: " + str(stwigs))
        db = DB_Access_Test()

        jobs = []

        for t in stwigs:
            iter_num = stwigs.index(t)
            process = Process(target=db.match_finding_process_filtered, args=(t, return_dict, STwig_query_neighbor_labels, query_graph, iter_num, used_stwigs, ))
            jobs.append(process)

        for j in jobs:
            j.start()
            j.join()

        print("Results from multiprocessing: ")
        for item in return_dict.values():
            for i in item:
                print(i)



        print("\n============== End of Option 93 execution =================")


    elif option == 94:
        print("\n================= Option 94 commencing... =================")
        query_graph_gen = Query_Graph_Generator()
        # query_graph = query_graph_gen.gen_zhaosun_query_graph()
        # query_graph = query_graph_gen.gen_small_graph_query_graph()
        query_graph = query_graph_gen.gen_RI_query_graph()
        print("Query graph node ID's and labels: ")
        print(query_graph.nodes(data=True))

        manager = Manager()
        return_dict = manager.dict()
        used_stwigs = manager.list()
        STwig_query_neighbor_labels = manager.list()
        shared_sorted_leafs_to_be_roots = manager.list()

        lock = Lock()

        STwig_algorithm = STwig_Algorithm(query_graph, return_dict, used_stwigs, STwig_query_neighbor_labels, lock)
        stwigs = STwig_algorithm.STwig_Order_Selection()
        print("STwigs generated by STwig_Order_Selection() from the query graph: " + str(stwigs))
        db = DB_Access_Test()

        jobs = []

        # Paralelizat, fara filtrare.
        # producer = Process(target=db.match_finding_process_producer, args=(stwigs[0], return_dict, STwig_query_neighbor_labels, query_graph, 0, used_stwigs, lock, ))
        # producer2 = Process(target=db.match_finding_process_producer, args=(stwigs[1], return_dict, STwig_query_neighbor_labels, query_graph, 0, used_stwigs, lock, ))
        # producer3 = Process(target=db.match_finding_process_producer, args=(stwigs[2], return_dict, STwig_query_neighbor_labels, query_graph, 0, used_stwigs, lock, ))
        # # filterer = Process(target=db.filter_results_process, args=(stwigs[1], return_dict, stwigs[1][1], query_graph, used_stwigs, lock, shared_sorted_leafs_to_be_roots, ))
        # prod_com = [producer, producer2, producer3]
        #
        # # start_time = timer()
        #
        # for pc in prod_com:
        #     pc.start()
        #     # pc.join()
        #
        # for pc in prod_com:
        #     pc.join()


        # print()
        # print("STwig_query_neighbor_labels - must not be empty")
        # print(STwig_query_neighbor_labels)


        # Neparalelizat, cu filtrare.
        for t in stwigs:
            iter_num = stwigs.index(t)
            process = Process(target=db.match_finding_process_producer, args=(stwigs[0], return_dict, STwig_query_neighbor_labels, query_graph, 0, used_stwigs, lock, ))
            jobs.append(process)

        start_time = timer()
        for j in jobs:
            j.start()
            # print('PID is ' + str(j.pid))
            # print(os.getpid())
            # started_processes.append(j)
            # print(j.is_alive())
            j.join()
        #
        # total_time = (timer() - start_time) * 1000
        #

        # f2 = open("f2.txt", "w+")
        print("Results from STwig Algorithm: ")
        for item in return_dict.values():
            # print(item)
            for i in item:
                print(i)
                # f2.write(str(i)+"\n")
        # f2.close()

        # print()
        # print("Total exec time: " + str(total_time))

        # print()
        # print("used_stwigs: ")
        # for us in used_stwigs:
        #     print(us)

        # for q in stwigs:
        # q = stwigs[1]
        # STwig_query_neighbors = q[1]
        # STwig_algorithm.filter_results(q, STwig_query_neighbors)


        print("\n============== End of Option 94 execution =================")


    elif option == 10:
        print("\n================= Option 10 commencing... =================")
        # print("Are these the query graph STWIGS?")
        query_graph_gen = Query_Graph_Generator()
        query_graph = query_graph_gen.gen_zhaosun_query_graph()
        test2 = neo4j_test_2()
        query_graph_gen = Query_Graph_Generator()
        query_graph = query_graph_gen.gen_zhaosun_query_graph()
        splits = test2.Query_Graph_Split(query_graph)
        for s in splits:
            print(str(splits))
        print("\n============== End of Option 10 execution =================")

    elif option == 11:
        file = "notepad.exe neo4j_db\\docker-compose.yml"
        os.system(file)

    elif option == 12:
        print("\nVF2 Algorithm: ")
        f_12 = open("file_VF2 Algorithm output.txt", "w+")

        # TRANSFORMA IN INT DIN STR IN CREAREA GRAFULUI NX! - Facut.

        # M = [["0", "0"]]  # Test de corectitudine. Ar trebui sa dea un M in care toate match-urile sa aiba elemente egale, practic sa imi returneze toate nodurile query asociate cu ele insasi.
        # M = [["0", "1173"]] # Test al timpului de executie.
        # vf2 = VF2Algorithm(M, 'graph_to_RI_db.txt', 'Homo_sapiens_udistr_32.gfd', 'RI')

        # M = [["1","1"]]
        # M = [[1, 5]]
        # M = [["1","9"]]
        # print(M)

        # vf2 = VF2Algorithm(M)
        # vf2.subGraphSearch(M)

        # vf2 = VF2Algorithm(M, 'small_query_graph_VF2.txt', 'small_data_graph_VF2.txt', 'RI')
        # vf2.subGraphSearch(M)


        M = []
        results = []
        # print("Query graph choice: for Small data graph or RI data graph? (sm/ri)")
        # graph_choice = str(input())
        start_time_VF2 = timer()
        if len(M) == 0:
            # Pentru radacini nu am mai facut pruning!
            # Pentru fiecare radacina din lista de radacini,
            # din rezultatul final voi elimina radacinile care nu au fost folosite
            # pentru executia respectiva a algoritmului.

            M_list_main = []

            print("\nRoots search beginning: ")
            # vf2 = VF2Algorithm(M, 'small_query_graph_VF2.txt', 'small_data_graph_VF2.txt', 'RI')
            # exit(0)

            # vf2 = VF2Algorithm(M, graph_choice)
            vf2 = VF2Algorithm(M)


            roots = vf2.subGraphSearch(M)[1]
            vf2.results_dict.clear()

            print()
            print("Roots found: ")
            print(roots)
            print()
            # print("Selected root: ")
            for root in roots:
                # print(root)

                # M2 = [[1773, root]] # Algoritmul va schimba al doilea element doar.
                # print("M2 = " + str(M2))

                # if graph_choice == "ri":

                # Pentru prima serie de teste ale Art 2 - STwig si VF2.
                # M2 = [[1773, root]]
                # M2 = [[2462, root]]
                # M2 = [[0, root]]

                # Pentru a doua serie de teste ale Art 2 - STwig si VF2
                # M2 = [[7711, root]]
                # M2 = [[2670, root]]
                # M2 = [[4164, root]]
                # M2 = [[5636, root]]
                # M2 = [[11965, root]]

                # M2 = [[11041, root]]
                # M2 = [[7563, root]]
                # M2 = [[6880, root]]
                M2 = [[58, root]]
                # M2 = [[979, root]]

                # M2 = [[10881, root]] # Acest graf blocheaza laptop-ul - STwig alg
                # M2 = [[3719, root]] # Dupa 12 ore nu a terminat executia - STwig alg


                # Testare GNS2 si VF2
                # M2 = [[11041, root]] # Graf defect, GNS bucla infinita pt trei, patru sau cinci muchii
                # M2 = [[1773, root]]
                # M2 = [[8028, root]]


                # Testare GNS1 si VF2 pentru Art 3 - GNS1.
                # ok
                # M2 = [[11041, root]]

                # ok
                # M2 = [[8028, root]]

                # ok
                # M2 = [[2850, root]]

                # ok
                # M2 = [[1773, root]]

                # ok
                # M2 = [[0, root]]

                # ok
                # M2 = [[2462, root]]

                # ok
                # M2 = [[11000, root]]

                # ok
                # M2 = [[5157, root]]

                # ok
                # M2 = [[6954, root]]

                # ok
                # M2 = [[3842, root]]


                    # print()
                    # print("Query root node: " + str(root))

                # vf2 = VF2Algorithm(M, 'small_query_graph_VF2.txt', 'small_data_graph_VF2.txt', 'RI')
                # vf2_2 = VF2Algorithm(M2, graph_choice)
                vf2_2 = VF2Algorithm(M2)

                execution_flag = vf2_2.subGraphSearch(M2)
                M_list_main.append(execution_flag)
                # vf2 = None

                # Pentru small graph
                # results.append([["Query root: " + "1"], ["Data root: " + str(root)], [list(vf2_2.results_dict.items())[1:]]])
                # Pentru RI graph
                # results.append([["Query root: " + "1773"], ["Data root: " + str(root)], [list(vf2_2.results_dict.items())[1:]]])
                if execution_flag == None:
                    # if graph_choice == "sm":
                    #     print(Fore.LIGHTGREEN_EX + str([["Query root: " + "1"], ["Data root: " + str(root)],
                    #                                     [list(vf2_2.results_dict.items())[1:]]]))
                    #     print(Style.RESET_ALL)

                    # if graph_choice == "ri":
                    # if len(list(vf2_2.results_dict.items())) > 0:

                    leafs = copy.deepcopy(list(vf2_2.results_dict.items()))
                    leafs.insert(0, root)
                    res = copy.deepcopy(leafs)
                    # print("Results from VF2 Algorithm: ")
                    res_general = []
                    if len(res) == len(vf2_2.queryGraph.nodes()):
                        # print(Fore.LIGHTGREEN_EX + "Data root: " + str(root))
                        for res_element in res[1:]:
                            res_general.append(res_element[1])
                        # print(res_general)
                        root_as_list = [root]
                        res_general.insert(0, root_as_list)
                        # for cartesian_prod_element in itertools.product(res_general[0], res_general[1], res_general[2]):
                        for cartesian_prod_element in itertools.product(*res_general): # Folosire asterisk pentru ca functia de produs cartezian sa ia in considerare sublistele din lista res_general:
                                                                                       # https://stackoverflow.com/questions/533905/get-the-cartesian-product-of-a-series-of-lists

                            # print(cartesian_prod_element)
                            for cpe_elem in cartesian_prod_element:
                                f_12.write(str(cpe_elem) + " ")
                            f_12.write("\n")
                        # print(len(res))
                        # print(list(vf2_2.results_dict.items())[0])
                        # print(Style.RESET_ALL)
                        vf2_2.results_dict.clear()


        total_time_sec = timer() - start_time_VF2
        # print("Execution time for VF2 Algorithm (seconds): ")
        # print(total_time_sec)
        f_12_2 = open("file_VF2 Algorithm execution times.txt", "a")
        f_12_2.write(str(total_time_sec) + " ")
        f_12_2.write("\n")
        f_12_2.close()

                    # print(Fore.LIGHTBLUE_EX + "\nShow results found until now? (y/n): ")
                    # i = input()
                    # if i == "y":
                    #     break
                    # print(Style.RESET_ALL)

            # print(Fore.GREEN + "\nFinal results: ")
            # for result in results:
            #     print(result)
            # print(Style.RESET_ALL)



        # elif option == 13:
        #     ##################################################################
        #
        #     # GRAFUL DATA DIN NEO4J
        #     # neograph_data = Graph("bolt://127.0.0.1:7690", auth=("neo4j", "changeme")) # Data Graph RI - Cluster Neo4J
        #     neograph_data = Graph("bolt://127.0.0.1:7687",
        #                           auth=("neo4j", "changeme"))  # Data Graph RI - O singura instanta de Neo4J
        #
        #     cqlQuery = "MATCH p=(n)-[r:PPI]->(m) return n.node_id, m.node_id"
        #     result = neograph_data.run(cqlQuery).to_ndarray()
        #     edge_list = result.tolist()
        #     # print("edge_list: ")
        #     # print(edge_list)
        #     edge_list_integer_ids = []
        #     for string_edge in edge_list:
        #         edge_list_integer_ids.append([int(i) for i in string_edge])
        #     # print("edge_list_integer_ids: ")
        #     # print(edge_list_integer_ids)
        #
        #     dataGraph = nx.Graph()
        #     dataGraph.add_edges_from(sorted(edge_list_integer_ids))
        #     cqlQuery2 = "MATCH (n) return n.node_id, n.node_label"
        #     result2 = neograph_data.run(cqlQuery2).to_ndarray()
        #     # print("result2: ")
        #     # print(result2)
        #     node_ids_as_integers_with_string_labels = []
        #     for node in result2:
        #         # print(node[0])
        #         node_ids_as_integers_with_string_labels.append([int(node[0]), node[1]])
        #     # print("node_ids_as_integers_with_string_labels: ")
        #     # print(node_ids_as_integers_with_string_labels)
        #
        #     node_attr_dict = OrderedDict(sorted(node_ids_as_integers_with_string_labels))
        #     nx.set_node_attributes(dataGraph, node_attr_dict, 'label')
        #     #############################################################################
        #
        #     # # FUNCTIONAL:
        #     # query_stwig_1 = [1, 2, 3, 4]
        #     # # query_stwig_1 = [1, 2, 3]
        #     # # query_stwig_1 = [2, 3, 4]
        #     # # query_stwig_1 = [1, 2]
        #     # # query_stwig_1 = [3, 10]
        #     # # query_stwig_1 = [4, 10]
        #     #
        #     #
        #     # print("Query STwig: " + str(query_stwig_1))
        #     # # Label-ul radacinii
        #     # root_label = small_graph.node[query_stwig_1[0]]['label']
        #     # # Label-urile vecinilor din lista
        #     # neighbor_labels = []
        #     # for n in query_stwig_1[1:]:
        #     #     neighbor_labels.append(small_graph.node[n]['label'])
        #     #
        #     # query_stwig_1_as_labels = []
        #     # query_stwig_1_as_labels.append(root_label)
        #     # for nl in neighbor_labels:
        #     #     query_stwig_1_as_labels.append(nl)
        #     # print("query_stwig_1_as_labels: " + str(query_stwig_1_as_labels))
        #     # print()
        #     # query_stwig_1_as_labels_source = copy.deepcopy(query_stwig_1_as_labels)
        #     #
        #     # query_stwig1_dict = OrderedDict(zip(query_stwig_1, query_stwig_1_as_labels_source))
        #     # print("query_stwig1_dict: ")
        #     # print(query_stwig1_dict.items())
        #     # print()
        #     # p_solution = []
        #     # complete_solutions = []
        #     # positions = OrderedDict().fromkeys([0,1,2,3])
        #     # positions[0] = []
        #     # positions[1] = []
        #     # positions[2] = []
        #     # positions[3] = []
        #     # print(positions.items())
        #     # node_list_aux = copy.deepcopy(list(small_graph.nodes()))
        #     #######################################################################################
        #
        #     # FUNCTIONAL:
        #     # query_stwig_1 = [1773, 1488, 1898, 2285]
        #
        #     # Aici cream un obiect graf query:
        #     query_graph_gen = Query_Graph_Generator()
        #     query_graph = query_graph_gen.gen_RI_query_graph()
        #     query_stwig_1 = list(query_graph.nodes())
        #     print("Query STwig: " + str(query_stwig_1))
        #     # Label-ul radacinii
        #     # root_label = dataGraph.node[query_stwig_1[0]]['label']
        #     root_label = query_graph.node[query_stwig_1[0]]['label']
        #     # Label-urile vecinilor din lista
        #     neighbor_labels = []
        #     for n in query_stwig_1[1:]:
        #         # neighbor_labels.append(dataGraph.node[n]['label'])
        #         neighbor_labels.append(query_graph.node[n]['label'])
        #
        #     query_stwig_1_as_labels = []
        #     query_stwig_1_as_labels.append(root_label)
        #     for nl in neighbor_labels:
        #         query_stwig_1_as_labels.append(nl)
        #     print("query_stwig_1_as_labels: " + str(query_stwig_1_as_labels))
        #     print()
        #     query_stwig_1_as_labels_source = copy.deepcopy(query_stwig_1_as_labels)
        #
        #     query_stwig1_dict = OrderedDict(zip(query_stwig_1, query_stwig_1_as_labels_source))
        #     print("query_stwig1_dict: ")
        #     print(query_stwig1_dict.items())
        #     print()
        #     p_solution = []
        #     complete_solutions = []
        #     positions = OrderedDict().fromkeys([0, 1, 2, 3])
        #     positions[0] = []
        #     positions[1] = []
        #     positions[2] = []
        #     positions[3] = []
        #     print("Positions log: ")
        #     print(positions.items())
        #     node_list_aux = copy.deepcopy(list(dataGraph.nodes()))
        #     ####################################################################################
        #
        #     # Fisier text:
        #     f1 = open("f1.txt", "w+")
        #
        #     # Executia algoritmului Backtracking:
        #     backtracking = Backtracking_STwig_Matching()
        #     try:
        #         # subgraph_search(p_solution, query_stwig1_dict, [], small_graph)
        #         start_time = timer()
        #         subgraph_search(p_solution, query_stwig1_dict, [], dataGraph)
        #         total_time = timer() - start_time
        #         print("Timp total de executare algoritm Backtracking: " + str(total_time) + " secunde.")
        #     except IndexError:
        #         tb = traceback.format_exc()
        #         print(tb)
        #     except SystemExit:
        #         exit(0)

        # elif option == 0:
        #     exit(code=0)

    elif option == 13:
        print("\n##### GR1 Algorithm execution #####")
        tools = tgri()

        # for pq in query_graph:
        #     print(pq)
        print()
        data_graph = tools.obtain_data_graph()
        # for pd in data_graph:
        #     print(pd)

        execution_times = []

        # Variabila "query_graph" poate sa contina un query graf intreg, sau mai multe bucati.

        # stackoverflow.com/questions/11700593/creating-files-and-directories-via-python
        # stackoverflow.com/questions/8024248/telling-python-to-save-a-txt-file-to-a-certain-directory-on-windows-and-mac

        # Rulare cu graf query intreg, fara descompunere
        # query_graph = tools.obtain_query_graph()
        # print(query_graph)
        # a0 = GR1_Algorithm(query_graph, data_graph, False, 'C:/Users/StationG/Desktop/Baterie Teste GR1_Algorithm/Test 0/')
        # a0.execute_gr1_algorithm()
        # execution_times.append(a0.get_execution_time_gr1_algorithm())
        # create_execution_times_and_avg_txt_file_with_dir('C:/Users/StationG/Desktop/Baterie Teste GR1_Algorithm/Test 0/', execution_times)

        # Rulare cu prima bucata a unui query STwig cu 4 noduri:
        # query_graph = tools.obtain_query_graph(wanted_parts=2)
        # query_graph_edges = [[7190,137], [7190,419], [7190,450]]
        # node_attr = ["3", "2", "11", "3"]
        # query_graph = obtain_query_graph(2)[0] # Variabila "query_graph" poate sa contina un query graf intreg, sau mai multe bucati.
        # a1 = GR1_Algorithm(query_graph[0], data_graph, False, 'C:/Users/StationG/Desktop/Baterie Teste GR1_Algorithm/Test 1/')
        # a1.execute_gr1_algorithm()
        # execution_times.append(a1.get_execution_time_gr1_algorithm())
        # create_execution_times_and_avg_txt_file_with_dir('C:/Users/StationG/Desktop/Baterie Teste GR1_Algorithm/Test 1/', execution_times)


        # Doua rulari succesive cu a doua jumatate query STwig
        # query_graph = tools.obtain_query_graph(2)[0] # Variabila "query_graph" poate sa contina un query graf intreg, sau mai multe bucati.
        # a2 =GR1_Algorithm(query_graph[1], data_graph, True, 'C:/Users/StationG/Desktop/Baterie Teste GR1_Algorithm/Test 2/')
        # a2.execute_gr1_algorithm()
        # execution_times.append(a2.get_execution_time_gr1_algorithm())
        # create_execution_times_and_avg_txt_file_with_dir('C:/Users/StationG/Desktop/Baterie Teste GR1_Algorithm/Test 2/', execution_times)

        # query_graph = tools.obtain_query_graph(2)[0] # Variabila "query_graph" poate sa contina un query graf intreg, sau mai multe bucati.
        # a3 =GR1_Algorithm(query_graph[1], data_graph, False, 'C:/Users/StationG/Desktop/Baterie Teste GR1_Algorithm/Test 2/')
        # a3.execute_gr1_algorithm()
        # execution_times.append(a3.get_execution_time_gr1_algorithm())
        # create_execution_times_and_avg_txt_file_with_dir('C:/Users/StationG/Desktop/Baterie Teste GR1_Algorithm/Test 2/', execution_times)

        # NU fac rulari succesive, apare timp in plus de la a doua bucata
        # Nu fac reunirea rezultatelor pt ca dureaza prea mult pentru acest query graph STwig.
        # Am testat si metoda de creare al mediei respective.
        query_graph = tools.obtain_query_graph_stwig(wanted_parts=5)[0] # Listele sunt stocate pe prima pozitie al unei liste mai mari, de aceea folosesc [0].

        # a4 = GR1_Algorithm(query_graph[0], data_graph, False, 'C:/Users/StationG/Desktop/24 oct 2020 Baterie Teste GR1_Algorithm/Test 30/I parte graf query STwig/')
        # a4.execute_gr1_algorithm()

        # a5 = GR1_Algorithm(query_graph[1], data_graph, False, 'C:/Users/StationG/Desktop/24 oct 2020 Baterie Teste GR1_Algorithm/Test 30/II-a parte graf query STwig/')
        # a5.execute_gr1_algorithm()

        # a6 = GR1_Algorithm(query_graph[2], data_graph, False, 'C:/Users/StationG/Desktop/24 oct 2020 Baterie Teste GR1_Algorithm/Test 30/III-a parte graf query STwig/')
        # a6.execute_gr1_algorithm()

        # a7 = GR1_Algorithm(query_graph[3], data_graph, False, 'C:/Users/StationG/Desktop/24 oct 2020 Baterie Teste GR1_Algorithm/Test 30/IV-a parte graf query STwig/')
        # a7.execute_gr1_algorithm()

        # a8 = GR1_Algorithm(query_graph[4], data_graph, False, 'C:/Users/StationG/Desktop/24 oct 2020 Baterie Teste GR1_Algorithm/Test 30/V-a parte graf query STwig/')
        # a8.execute_gr1_algorithm()

        # Obtinerea mediei aritmetice al timpilor de executie.
        # Pentru prima parte.
        tools.create_execution_times_and_avg_txt_file_at_dir_path("GR1_Algorithm",
                                                                  'C:/Users/StationG/Desktop/24 oct 2020 Baterie Teste GR1_Algorithm/Test 30/I parte graf query STwig/file_GR1_Algorithm_execution_times.txt',
                                                                  'C:/Users/StationG/Desktop/24 oct 2020 Baterie Teste GR1_Algorithm/Test 30/I parte graf query STwig/')
        # Pentru a doua parte.
        tools.create_execution_times_and_avg_txt_file_at_dir_path("GR1_Algorithm",
                                                                  'C:/Users/StationG/Desktop/24 oct 2020 Baterie Teste GR1_Algorithm/Test 30/II-a parte graf query STwig/file_GR1_Algorithm_execution_times.txt',
                                                                  'C:/Users/StationG/Desktop/24 oct 2020 Baterie Teste GR1_Algorithm/Test 30/II-a parte graf query STwig/')
        # Pentru a treia parte.
        tools.create_execution_times_and_avg_txt_file_at_dir_path("GR1_Algorithm",
                                                                  'C:/Users/StationG/Desktop/24 oct 2020 Baterie Teste GR1_Algorithm/Test 30/III-a parte graf query STwig/file_GR1_Algorithm_execution_times.txt',
                                                                  'C:/Users/StationG/Desktop/24 oct 2020 Baterie Teste GR1_Algorithm/Test 30/III-a parte graf query STwig/')
        # Pentru a patra parte.
        tools.create_execution_times_and_avg_txt_file_at_dir_path("GR1_Algorithm",
                                                                  'C:/Users/StationG/Desktop/24 oct 2020 Baterie Teste GR1_Algorithm/Test 30/IV-a parte graf query STwig/file_GR1_Algorithm_execution_times.txt',
                                                                  'C:/Users/StationG/Desktop/24 oct 2020 Baterie Teste GR1_Algorithm/Test 30/IV-a parte graf query STwig/')
        # Pentru a cincea parte.
        tools.create_execution_times_and_avg_txt_file_at_dir_path("GR1_Algorithm",
                                                                  'C:/Users/StationG/Desktop/24 oct 2020 Baterie Teste GR1_Algorithm/Test 30/V-a parte graf query STwig/file_GR1_Algorithm_execution_times.txt',
                                                                  'C:/Users/StationG/Desktop/24 oct 2020 Baterie Teste GR1_Algorithm/Test 30/V-a parte graf query STwig/')

        # Reunirea rezultatelor
        # list_of_paths = ["C:/Users/StationG/Desktop/16 oct 2020 Baterie Teste GR1_Algorithm/Test 21/Prima parte graf query STwig/file_GR1_Algorithm_output.txt",
        #                  "C:/Users/StationG/Desktop/16 oct 2020 Baterie Teste GR1_Algorithm/Test 21/A doua parte graf query STwig/file_GR1_Algorithm_output.txt"]
        # r1 = tools.reunion_of_query_STwig_parts_results(list_of_paths)
        # tools.create_txt_file_reunited_results_at_dir_path(r1, "C:/Users/StationG/Desktop/16 oct 2020 Baterie Teste GR1_Algorithm/Rezultate reunite/", "file_GR1_Algorithm_reunited_results")
        # # print(r1)

    elif option == 14:
############################ Din GR1 Algorithm ##########################################################
        print("\n##### GR2 Algorithm execution #####")

        tools = tgri()
        print()
        data_graph = tools.obtain_data_graph()
        # for pd in data_graph:
        #     print(pd)

        execution_times = []

        # Variabila "query_graph" poate sa contina un query graf intreg, sau mai multe bucati.

        # stackoverflow.com/questions/11700593/creating-files-and-directories-via-python
        # stackoverflow.com/questions/8024248/telling-python-to-save-a-txt-file-to-a-certain-directory-on-windows-and-mac

        # Rulare cu graf query intreg, fara descompunere
        query_graph = tools.obtain_query_graph_non_stwig()
        # print(query_graph)
        a0 = GR2_Algorithm(query_graph, data_graph, False, 'C:/Users/StationG/Desktop/30 IAN 2021 Baterie Teste Finale RI Bos_taurus PPI GR2_Algorithm/Test 5/A treia bucata query/')
        a0.execute_gr2_algorithm()

        # Rulare cu despartirea grafului query in mai multe bucati.
        # query_graph = tools.obtain_query_graph_stwig(wanted_parts=2)[0]  # Listele sunt stocate pe prima pozitie al unei liste mai mari, de aceea folosesc [0].
        # print(query_graph)
        # a1 = GR2_Algorithm(query_graph[0], data_graph, False, 'C:/Users/StationG/Desktop/20 IAN 2021 Baterie Teste Finale RI Human PPI GR2_Algorithm/Test 5/')
        # a1.execute_gr2_algorithm()

        # Pentru calculul automat al mediei aritmetice al timpilor de executie:
        # Trebuie executat dupa numarul de teste dorit per graf query.
        # execution_times.append(a0.get_execution_time_gr2_algorithm())
        # tools.create_execution_times_and_avg_txt_file_with_dir('C:/Users/graiul/Desktop/Baterie Teste GR2_Algorithm/Test 3/', execution_times)
        # tools.create_execution_times_and_avg_txt_file_at_dir_path()


############################ Din GR1 Algorithm ##########################################################



if __name__ == '__main__':
    main()